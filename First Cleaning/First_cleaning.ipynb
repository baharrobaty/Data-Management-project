{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779c8168-8cf2-454e-be81-e97f4360fe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Offense Case Type Offense Date Offense Time Violation Charge Code  \\\n",
      "0                NT    10/1/2023      0:26:00                 60110   \n",
      "1                TR    10/1/2023     13:40:00                   710   \n",
      "2                TR    10/1/2023     16:39:00                 32210   \n",
      "3                TR    10/1/2023     17:04:00                   610   \n",
      "4                OR    10/1/2023     10:26:00                 64111   \n",
      "\n",
      "                Offense Charge Description       Offense Street Name  \\\n",
      "0                      Public Intoxication            4905 TERI ROAD   \n",
      "1                            Ran Red Light       4010 SOUTHWEST PKWY   \n",
      "2  Crossing Property To Turn Right Or Left         2414 S LAMAR BLVD   \n",
      "3                            Ran Stop Sign          BLUE CREST DRIVE   \n",
      "4                        Animal - At Large  6600 BLOCK ASHLAND DRIVE   \n",
      "\n",
      "  Offense Cross Street  School Zone  Construction Zone Case Closed   Race  \\\n",
      "0                  NaN        False              False        TERM  White   \n",
      "1                  NaN        False              False        TERM  White   \n",
      "2                  NaN        False              False        TERM  White   \n",
      "3      GOODRICH AVENUE        False              False        TERM  White   \n",
      "4                  NaN        False              False        TERM  White   \n",
      "\n",
      "  Defendant Gender                    Agency Officer Code  \n",
      "0             Male  Austin Police Department         9711  \n",
      "1           Female  Austin Police Department         9441  \n",
      "2             Male  Austin Police Department         7238  \n",
      "3             Male  Austin Police Department         7238  \n",
      "4           Female  Austin Police Department         7078  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_court = pd.read_csv(r'C:\\courses\\DataManagement and Vis\\project\\Municipal_Court_Caseload_Information_FY_2023.csv')\n",
    "print(df_court.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd00fa0-dc49-458b-b67f-b31e89b4c722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             STREET  POSTCODE    CITY\n",
      "0  DOYLE OVERTON RD     78719  Austin\n",
      "1           MAHA RD     78719  Austin\n",
      "2       POCMONT TRL     78719  Austin\n",
      "3         EVELYN RD     78747  Austin\n",
      "4    S SH  45 E  WB     78747  Austin\n"
     ]
    }
   ],
   "source": [
    "df_street_zip = pd.read_csv(r'C:\\courses\\DataManagement and Vis\\project\\austin_street_to_zip_mapping.csv')\n",
    "print(df_street_zip.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1214e55f-8822-42c1-80ff-6511f37fa971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "replacements =  {\n",
    "    \"ROAD\": \"RD\", \"RD\": \"RD\",\n",
    "    \"STREET\": \"ST\", \"ST\": \"ST\",\n",
    "    \"AVENUE\": \"AVE\", \"AVE\": \"AVE\",\n",
    "    \"DRIVE\": \"DR\", \"DR\": \"DR\",\n",
    "    \"COURT\": \"CT\", \"CT\": \"CT\",\n",
    "    \"LANE\": \"LN\", \"LN\": \"LN\",\n",
    "    \"CIRCLE\": \"CIR\", \"CIR\": \"CIR\",\n",
    "    \"TRAIL\": \"TRL\", \"TRL\": \"TRL\",\n",
    "    \"PARKWAY\": \"PKWY\", \"PKWY\": \"PKWY\",\n",
    "    \"HIGHWAY\": \"HWY\", \"HWY\": \"HWY\",\n",
    "    \"PLACE\": \"PL\", \"PL\": \"PL\",\n",
    "    \"PATH\": \"PATH\",\n",
    "    \"WAY\": \"WAY\",\n",
    "    \"LOOP\": \"LOOP\",\n",
    "    \"COVE\": \"CV\", \"CV\": \"CV\",\n",
    "\n",
    "    # directions (important!)\n",
    "    \"NORTH\": \"N\", \"N\": \"N\",\n",
    "    \"SOUTH\": \"S\", \"S\": \"S\",\n",
    "    \"EAST\": \"E\", \"E\": \"E\",\n",
    "    \"WEST\": \"W\", \"W\": \"W\",\n",
    "    \"NORTHEAST\": \"NE\", \"NE\": \"NE\",\n",
    "    \"NORTHWEST\": \"NW\", \"NW\": \"NW\",\n",
    "    \"SOUTHEAST\": \"SE\", \"SE\": \"SE\",\n",
    "    \"SOUTHWEST\": \"SW\", \"SW\": \"SW\",\n",
    "\n",
    "    # lane directions\n",
    "    \"NB\": \"NB\", \"SB\": \"SB\", \"EB\": \"EB\", \"WB\": \"WB\"\n",
    "}\n",
    "\n",
    "direction_garbage = {\n",
    "   \"BLOCK\", \"NB\", \"SB\", \"EB\", \"WB\", \"NORTHBOUND\", \"SOUTHBOUND\", \"EASTBOUND\", \"WESTBOUND\"\n",
    "}\n",
    "ordinals = {\n",
    "    \"FIRST\": \"1ST\", \"SECOND\": \"2ND\", \"THIRD\": \"3RD\", \"FOURTH\": \"4TH\",\n",
    "    \"FIFTH\": \"5TH\", \"SIXTH\": \"6TH\", \"SEVENTH\": \"7TH\", \"EIGHTH\": \"8TH\",\n",
    "    \"NINTH\": \"9TH\", \"TENTH\": \"10TH\"\n",
    "}\n",
    "\n",
    "def clean_and_normalize(s):\n",
    "    if pd.isna(s) or s == 'nan':\n",
    "        return s\n",
    "\n",
    "    s = s.upper()\n",
    "\n",
    "    # deleting numbers in first position with a space \n",
    "    s = re.sub(r\"^\\d+\\s+\", \"\", s)\n",
    "\n",
    "    # deleting punctuations\n",
    "    s = re.sub(r\"[^\\w\\s]\", \"\", s)\n",
    "\n",
    "    tokens = s.split()\n",
    "    clean_tokens = []\n",
    "\n",
    "    for i, t in enumerate(tokens):\n",
    "        # deleting noises (NB, SB, etc)\n",
    "        if t in direction_garbage:\n",
    "            continue\n",
    "        #FIRST -> 1ST\n",
    "        t = ordinals.get(t, t)\n",
    "\n",
    "        # correctint the abbrevations (ROAD -> RD)\n",
    "        t = replacements.get(t, t)\n",
    "\n",
    "        clean_tokens.append(t)\n",
    "\n",
    "    return \" \".join(clean_tokens).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e986d553-5efe-40ef-9023-870c8a1509b4",
   "metadata": {},
   "source": [
    "##Clean and normalize main dataset's street name Municipal_Court"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf990c8-d56a-41d8-8a5e-78c3fd2b7360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in first dataset Municipal_Court: 225624\n",
      "Number of rows after deleting duplicated names: 5449\n"
     ]
    }
   ],
   "source": [
    "df_court[\"street_clean1\"] = df_court[\"Offense Street Name\"].apply(clean_and_normalize)\n",
    "\n",
    "count_before1 = len(df_court)\n",
    "#removing duplicated streets\n",
    "df1_unique = df_court.drop_duplicates(subset=[\"street_clean1\"])\n",
    "count_after1 = len(df1_unique)\n",
    "\n",
    "print(f\"Total number of rows in first dataset Municipal_Court: {count_before1}\")\n",
    "print(f\"Number of rows after deleting duplicated names: {count_after1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb10952-8055-4f24-90c4-4f425bd90847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_unique['street_clean1'].to_csv('df1_unique_streets_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1217d8de-5a2f-4de4-aa79-fc8c52a44a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      street_clean1\n",
      "0           TERI RD\n",
      "1           SW PKWY\n",
      "2      S LAMAR BLVD\n",
      "3     BLUE CREST DR\n",
      "4        ASHLAND DR\n",
      "5       W PARMER LN\n",
      "6     LEVANDER LOOP\n",
      "7           LAZY ON\n",
      "8  WALSH TARLTON LN\n",
      "9      S MOPAC EXPY\n"
     ]
    }
   ],
   "source": [
    "df1_unique_streets_only = pd.read_csv(r'C:\\Users\\Utente\\df1_unique_streets_only.csv')\n",
    "print(df1_unique_streets_only.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98c0b9-6c4b-4b75-a087-6b056770e642",
   "metadata": {},
   "source": [
    "##Clean and normalize second dataset's street name austin_street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d24f4b-3eb4-4a0e-8067-f9bca873673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with an empty string, then clean\n",
    "df_street_zip[\"street_clean2\"] = df_street_zip[\"STREET\"].fillna(\"\").astype(str).str.upper().str.strip()\n",
    "\n",
    "# normalization function now receives \"\" instead of a float\n",
    "df_street_zip[\"street_clean2\"] = df_street_zip[\"street_clean2\"].apply(clean_and_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c423b99b-12ee-47b2-a603-7d076e77aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in second dataset austin_street: 11840\n",
      "Number of rows after deleting duplicated names: 11773\n"
     ]
    }
   ],
   "source": [
    "count_before2 = len(df_street_zip)\n",
    "\n",
    "#removing duplicated streets\n",
    "df2_unique = df_street_zip.drop_duplicates(subset=[\"street_clean2\", \"POSTCODE\"]) #there are equal street names with diffretnt zipcode, so they are not unique place\n",
    "\n",
    "count_after2 = len(df2_unique)\n",
    "\n",
    "print(f\"Total number of rows in second dataset austin_street: {count_before2}\")\n",
    "print(f\"Number of rows after deleting duplicated names: {count_after2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c742ff54-5eb5-43f1-a672-64322cb863de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_unique[['street_clean2', 'POSTCODE']].to_csv('df2_unique_streets_zipcode.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa1e08b-c4cc-4708-bb58-39b394353caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      street_clean2  POSTCODE\n",
      "0  DOYLE OVERTON RD     78719\n",
      "1           MAHA RD     78719\n",
      "2       POCMONT TRL     78719\n",
      "3         EVELYN RD     78747\n",
      "4         S SH 45 E     78747\n",
      "5     S SH 130 SVRD     78719\n",
      "6      MAHA LOOP RD     78719\n",
      "7      S US 183 HWY     78719\n",
      "8      S US 183 HWY     78747\n",
      "9    TOM SASSMAN RD     78747\n"
     ]
    }
   ],
   "source": [
    "df2_unique_streets_zipcode = pd.read_csv(r'C:\\Users\\Utente\\df2_unique_streets_zipcode.csv')\n",
    "print(df2_unique_streets_zipcode.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3793bc9-d8aa-4a02-945f-1e92585e3011",
   "metadata": {},
   "source": [
    "##to find how many unique cities matches in 2 different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6feff4fc-b1f4-42bd-ae48-6f8cf125fb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: 1987\n"
     ]
    }
   ],
   "source": [
    "#Integerating 2 datasets\n",
    "common = set(df1_unique_streets_only[\"street_clean1\"]) & set(df2_unique_streets_zipcode[\"street_clean2\"])\n",
    "# Remove 'nan' or empty strings if they aren't real cities -> Data Quality\n",
    "common.discard('NAN') \n",
    "common.discard('')\n",
    "common.discard('nan')\n",
    "print(\"Matches:\", len(common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aca0664d-a296-4676-bf91-d0254db343a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common ZIPs: 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{78701,\n",
       " 78702,\n",
       " 78703,\n",
       " 78704,\n",
       " 78705,\n",
       " 78721,\n",
       " 78722,\n",
       " 78723,\n",
       " 78724,\n",
       " 78725,\n",
       " 78726,\n",
       " 78727,\n",
       " 78728,\n",
       " 78729,\n",
       " 78730,\n",
       " 78731,\n",
       " 78732,\n",
       " 78733,\n",
       " 78735,\n",
       " 78736,\n",
       " 78737,\n",
       " 78738,\n",
       " 78739,\n",
       " 78741,\n",
       " 78742,\n",
       " 78744,\n",
       " 78745,\n",
       " 78746,\n",
       " 78747,\n",
       " 78748,\n",
       " 78749,\n",
       " 78750,\n",
       " 78751,\n",
       " 78752,\n",
       " 78753,\n",
       " 78754,\n",
       " 78756,\n",
       " 78757,\n",
       " 78758,\n",
       " 78759}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neigh = pd.read_csv(r'C:\\courses\\DataManagement and Vis\\project\\austin_zip_to_neighborhood_full.csv')\n",
    "df_pop = pd.read_csv(r'C:\\courses\\DataManagement and Vis\\project\\austin_population_by_zip_scraped.csv')\n",
    "valid_pop = df_pop[df_pop[\"Population\"] > 0]\n",
    "\n",
    "zip_neigh = set(df_neigh[\"ZIP_Code\"])\n",
    "zip_pop_valid = set(valid_pop[\"ZIP_Code\"])\n",
    "zip_street = set(df2_unique_streets_zipcode[\"POSTCODE\"])\n",
    "\n",
    "common_zips = zip_neigh & zip_pop_valid & zip_street\n",
    "\n",
    "print(\"Common ZIPs:\", len(common_zips))\n",
    "common_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24fc2591-f816-450f-b85f-9467d29eb677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP codes found in matched streets: 43\n",
      "ZIP codes in your valid pool (Neighborhood/Pop/Street): 40\n",
      "---\n",
      "Shared ZIP codes (Matches): 40\n"
     ]
    }
   ],
   "source": [
    "# 1. Get the set of ZIP codes associated ONLY with the streets in 'common'\n",
    "# We look at df2 to find the POSTCODE for every street that exists in 'common'\n",
    "zips_from_matched_streets = set(df2_unique_streets_zipcode[\n",
    "    df2_unique_streets_zipcode['street_clean2'].isin(common)\n",
    "]['POSTCODE'])\n",
    "\n",
    "# 2. Find the intersection between matched street ZIPs and valid pool (common_zips)\n",
    "final_overlap = zips_from_matched_streets & common_zips\n",
    "\n",
    "print(f\"ZIP codes found in matched streets: {len(zips_from_matched_streets)}\")\n",
    "print(f\"ZIP codes in your valid pool (Neighborhood/Pop/Street): {len(common_zips)}\")\n",
    "print(f\"---\")\n",
    "print(f\"Shared ZIP codes (Matches): {len(final_overlap)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320b721-9fb1-4bce-8c1c-ee405715768a",
   "metadata": {},
   "source": [
    "##Final cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a2d6306-be7a-47e2-927e-e18c5343065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_court['street_clean'] = df_court['Offense Street Name'].str.upper().str.strip()\n",
    "df2_unique_streets_zipcode['street_clean2'] = df2_unique_streets_zipcode['street_clean2'].str.upper().str.strip()\n",
    "df1_unique_streets_only['street_clean1'] = df1_unique_streets_only['street_clean1'].str.upper().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56892f7f-56df-4d1d-9091-8487bc818b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_with_zip = pd.merge(df_court, df2_unique_streets_zipcode\n",
    "                           [['street_clean2', 'POSTCODE']], left_on='street_clean', right_on='street_clean2', how='left')\n",
    "crimes_with_zip.rename(columns={'POSTCODE': 'ZIP_Code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56bc218e-eeb0-4492-ac3c-71ea5fdb8ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match rate (ZIP is found): 1.93%\n"
     ]
    }
   ],
   "source": [
    "match_rate = crimes_with_zip['ZIP_Code'].notna().mean() * 100\n",
    "print(f\"Match rate (ZIP is found): {match_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "449bbfbd-4a81-438e-8fa5-066e7ba5c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_with_neigh = pd.merge(crimes_with_zip, df_neigh, on='ZIP_Code', how='left')\n",
    "valid_pop = df_pop[df_pop['Population'] > 0][['ZIP_Code', 'Population']]\n",
    "crimes_integrated = pd.merge(crimes_with_neigh, valid_pop, on='ZIP_Code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6851fa62-2d55-44e3-8d17-6cdee6ef0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_by_neigh = crimes_integrated.groupby('Neighborhood').agg({\n",
    "    'Offense Case Type': 'count',  # crime nums \n",
    "    'Population': 'mean',\n",
    "    'Race': lambda x: x.value_counts().to_dict() if not x.empty else {}  # race distribution\n",
    "}).reset_index()\n",
    "crimes_by_neigh.rename(columns={'Offense Case Type': 'Crime_Count'}, inplace=True)\n",
    "crimes_by_neigh['Crime_Rate_per_1000'] = (crimes_by_neigh['Crime_Count'] / crimes_by_neigh['Population']) * 1000\n",
    "crimes_by_neigh = crimes_by_neigh.sort_values('Crime_Rate_per_1000', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e2aeeb8-7c1c-477d-8946-8c448bc1893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Storage\n",
    "crimes_integrated.to_csv('final_integrated_crimes.csv', index=False)\n",
    "crimes_by_neigh.to_csv('analysis_by_neighborhood.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f76893e-4ef9-48be-9dd6-c134b9306d5f",
   "metadata": {},
   "source": [
    "##First Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e5993e0-ae87-4bd9-9f4d-10f1468081e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integration is Done !\n",
      "Match rate: 1.9323013669747338 %\n",
      "\\  Neighborhoods with highest rate:\n",
      "              Neighborhood  Crime_Count    Population  \\\n",
      "6          Downtown Austin          345  11625.000000   \n",
      "8              East Austin          387  23556.532300   \n",
      "15            North Austin          475  45596.637895   \n",
      "24            South Austin          259  35019.069498   \n",
      "3               Cherrywood           48   6618.000000   \n",
      "23                Rosedale           61   8426.000000   \n",
      "0     Allandale, Crestview          158  23847.000000   \n",
      "29  Tarrytown, Clarksville          134  22194.000000   \n",
      "30            Wells Branch          131  25555.000000   \n",
      "11               Hyde Park           83  17071.000000   \n",
      "\n",
      "                                                 Race  Crime_Rate_per_1000  \n",
      "6   {'White': 117, 'Black': 20, 'WHITE': 9, 'Middl...            29.677419  \n",
      "8   {'White': 165, 'Black': 34, 'WHITE': 18, 'Asia...            16.428564  \n",
      "15  {'White': 178, 'Black': 16, 'WHITE': 14, 'Asia...            10.417435  \n",
      "24  {'White': 76, 'Black': 20, 'WHITE': 13, 'Other...             7.395970  \n",
      "3   {'White': 26, 'Black': 4, 'WHITE': 3, 'Asian':...             7.252947  \n",
      "23  {'White': 32, 'Black': 4, 'WHITE': 2, 'Unknown...             7.239497  \n",
      "0   {'White': 46, 'Black': 8, 'WHITE': 3, 'Native ...             6.625571  \n",
      "29  {'White': 39, 'Black': 7, 'Middle Eastern': 3,...             6.037668  \n",
      "30  {'White': 17, 'Black': 5, 'Asian': 3, 'WHITE':...             5.126198  \n",
      "11  {'White': 37, 'Black': 6, 'WHITE': 3, 'Hispani...             4.862047  \n"
     ]
    }
   ],
   "source": [
    "print(\"Integration is Done !\")\n",
    "print(\"Match rate:\", match_rate, \"%\")\n",
    "print(\"\\  Neighborhoods with highest rate:\")\n",
    "print(crimes_by_neigh.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
