{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779c8168-8cf2-454e-be81-e97f4360fe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Offense Case Type Offense Date Offense Time Violation Charge Code  \\\n",
      "0                NT    10/1/2023      0:26:00                 60110   \n",
      "1                TR    10/1/2023     13:40:00                   710   \n",
      "2                TR    10/1/2023     16:39:00                 32210   \n",
      "3                TR    10/1/2023     17:04:00                   610   \n",
      "4                OR    10/1/2023     10:26:00                 64111   \n",
      "\n",
      "                Offense Charge Description       Offense Street Name  \\\n",
      "0                      Public Intoxication            4905 TERI ROAD   \n",
      "1                            Ran Red Light       4010 SOUTHWEST PKWY   \n",
      "2  Crossing Property To Turn Right Or Left         2414 S LAMAR BLVD   \n",
      "3                            Ran Stop Sign          BLUE CREST DRIVE   \n",
      "4                        Animal - At Large  6600 BLOCK ASHLAND DRIVE   \n",
      "\n",
      "  Offense Cross Street  School Zone  Construction Zone Case Closed   Race  \\\n",
      "0                  NaN        False              False        TERM  White   \n",
      "1                  NaN        False              False        TERM  White   \n",
      "2                  NaN        False              False        TERM  White   \n",
      "3      GOODRICH AVENUE        False              False        TERM  White   \n",
      "4                  NaN        False              False        TERM  White   \n",
      "\n",
      "  Defendant Gender                    Agency Officer Code  \n",
      "0             Male  Austin Police Department         9711  \n",
      "1           Female  Austin Police Department         9441  \n",
      "2             Male  Austin Police Department         7238  \n",
      "3             Male  Austin Police Department         7238  \n",
      "4           Female  Austin Police Department         7078  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_court = pd.read_csv(r'C:\\courses\\DataManagement and Vis\\project\\Municipal_Court_Caseload_Information_FY_2023.csv')\n",
    "print(df_court.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd00fa0-dc49-458b-b67f-b31e89b4c722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             STREET  POSTCODE    CITY\n",
      "0  DOYLE OVERTON RD     78719  Austin\n",
      "1           MAHA RD     78719  Austin\n",
      "2       POCMONT TRL     78719  Austin\n",
      "3         EVELYN RD     78747  Austin\n",
      "4    S SH  45 E  WB     78747  Austin\n"
     ]
    }
   ],
   "source": [
    "df_street_zip = pd.read_csv(r'C:\\courses\\DataManagement and Vis\\project\\austin_street_to_zip_mapping.csv')\n",
    "print(df_street_zip.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1214e55f-8822-42c1-80ff-6511f37fa971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "replacements =  {\n",
    "    \"ROAD\": \"RD\", \"RD\": \"RD\",\n",
    "    \"STREET\": \"ST\", \"ST\": \"ST\",\n",
    "    \"AVENUE\": \"AVE\", \"AVE\": \"AVE\",\n",
    "    \"DRIVE\": \"DR\", \"DR\": \"DR\",\n",
    "    \"COURT\": \"CT\", \"CT\": \"CT\",\n",
    "    \"LANE\": \"LN\", \"LN\": \"LN\",\n",
    "    \"CIRCLE\": \"CIR\", \"CIR\": \"CIR\",\n",
    "    \"TRAIL\": \"TRL\", \"TRL\": \"TRL\",\n",
    "    \"PARKWAY\": \"PKWY\", \"PKWY\": \"PKWY\",\n",
    "    \"HIGHWAY\": \"HWY\", \"HWY\": \"HWY\",\n",
    "    \"PLACE\": \"PL\", \"PL\": \"PL\",\n",
    "    \"PATH\": \"PATH\",\n",
    "    \"WAY\": \"WAY\",\n",
    "    \"LOOP\": \"LOOP\",\n",
    "    \"COVE\": \"CV\", \"CV\": \"CV\",\n",
    "\n",
    "    # directions (important!)\n",
    "    \"NORTH\": \"N\", \"N\": \"N\",\n",
    "    \"SOUTH\": \"S\", \"S\": \"S\",\n",
    "    \"EAST\": \"E\", \"E\": \"E\",\n",
    "    \"WEST\": \"W\", \"W\": \"W\",\n",
    "    \"NORTHEAST\": \"NE\", \"NE\": \"NE\",\n",
    "    \"NORTHWEST\": \"NW\", \"NW\": \"NW\",\n",
    "    \"SOUTHEAST\": \"SE\", \"SE\": \"SE\",\n",
    "    \"SOUTHWEST\": \"SW\", \"SW\": \"SW\",\n",
    "\n",
    "}\n",
    "\n",
    "direction_garbage = {\n",
    "   \"BLOCK\", \"NB\", \"SB\", \"EB\", \"WB\", \"NORTHBOUND\", \"SOUTHBOUND\", \"EASTBOUND\", \"WESTBOUND\"\n",
    "}\n",
    "ordinals = {\n",
    "    \"FIRST\": \"1ST\", \"SECOND\": \"2ND\", \"THIRD\": \"3RD\", \"FOURTH\": \"4TH\",\n",
    "    \"FIFTH\": \"5TH\", \"SIXTH\": \"6TH\", \"SEVENTH\": \"7TH\", \"EIGHTH\": \"8TH\",\n",
    "    \"NINTH\": \"9TH\", \"TENTH\": \"10TH\"\n",
    "}\n",
    "\n",
    "def clean_and_normalize(s):\n",
    "    if pd.isna(s) or s == 'nan':\n",
    "        return s\n",
    "\n",
    "    s = s.upper()\n",
    "\n",
    "    # deleting numbers in first position with a space \n",
    "    s = re.sub(r\"^\\d+\\s+\", \"\", s)\n",
    "\n",
    "    # deleting punctuations\n",
    "    s = re.sub(r\"[^\\w\\s]\", \"\", s)\n",
    "\n",
    "    tokens = s.split()\n",
    "    clean_tokens = []\n",
    "\n",
    "    for i, t in enumerate(tokens):\n",
    "        # deleting noises (NB, SB, etc)\n",
    "        if t in direction_garbage:\n",
    "            continue\n",
    "        #FIRST -> 1ST\n",
    "        t = ordinals.get(t, t)\n",
    "\n",
    "        # correctint the abbrevations (ROAD -> RD)\n",
    "        t = replacements.get(t, t)\n",
    "\n",
    "        clean_tokens.append(t)\n",
    "\n",
    "    return \" \".join(clean_tokens).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e986d553-5efe-40ef-9023-870c8a1509b4",
   "metadata": {},
   "source": [
    "##Clean and normalize main dataset's street name Municipal_Court"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bf990c8-d56a-41d8-8a5e-78c3fd2b7360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in first dataset Municipal_Court: 225624\n",
      "Number of rows after deleting duplicated names: 5449\n"
     ]
    }
   ],
   "source": [
    "df_court[\"street_clean1\"] = df_court[\"Offense Street Name\"].apply(clean_and_normalize)\n",
    "\n",
    "count_before1 = len(df_court)\n",
    "#removing duplicated streets\n",
    "df1_unique = df_court.drop_duplicates(subset=[\"street_clean1\"])\n",
    "count_after1 = len(df1_unique)\n",
    "\n",
    "print(f\"Total number of rows in first dataset Municipal_Court: {count_before1}\")\n",
    "print(f\"Number of rows after deleting duplicated names: {count_after1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb10952-8055-4f24-90c4-4f425bd90847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_unique['street_clean1'].to_csv('df1_unique_streets_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1217d8de-5a2f-4de4-aa79-fc8c52a44a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      street_clean1\n",
      "0           TERI RD\n",
      "1           SW PKWY\n",
      "2      S LAMAR BLVD\n",
      "3     BLUE CREST DR\n",
      "4        ASHLAND DR\n",
      "5       W PARMER LN\n",
      "6     LEVANDER LOOP\n",
      "7           LAZY ON\n",
      "8  WALSH TARLTON LN\n",
      "9      S MOPAC EXPY\n"
     ]
    }
   ],
   "source": [
    "df1_unique_streets_only = pd.read_csv(r'C:\\Users\\Utente\\df1_unique_streets_only.csv')\n",
    "print(df1_unique_streets_only.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98c0b9-6c4b-4b75-a087-6b056770e642",
   "metadata": {},
   "source": [
    "##Clean and normalize second dataset's street name austin_street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d24f4b-3eb4-4a0e-8067-f9bca873673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with an empty string, then clean\n",
    "df_street_zip[\"street_clean2\"] = df_street_zip[\"STREET\"].fillna(\"\").astype(str).str.upper().str.strip()\n",
    "\n",
    "# normalization function now receives \"\" instead of a float\n",
    "df_street_zip[\"street_clean2\"] = df_street_zip[\"street_clean2\"].apply(clean_and_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c423b99b-12ee-47b2-a603-7d076e77aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in second dataset austin_street: 11840\n",
      "Number of rows after deleting duplicated names: 11773\n"
     ]
    }
   ],
   "source": [
    "count_before2 = len(df_street_zip)\n",
    "\n",
    "#removing duplicated streets\n",
    "df2_unique = df_street_zip.drop_duplicates(subset=[\"street_clean2\", \"POSTCODE\"]) #there are equal street names with diffretnt zipcode, so they are not unique place\n",
    "\n",
    "count_after2 = len(df2_unique)\n",
    "\n",
    "print(f\"Total number of rows in second dataset austin_street: {count_before2}\")\n",
    "print(f\"Number of rows after deleting duplicated names: {count_after2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c742ff54-5eb5-43f1-a672-64322cb863de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_unique[['street_clean2', 'POSTCODE']].to_csv('df2_unique_streets_zipcode.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fa1e08b-c4cc-4708-bb58-39b394353caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      street_clean2  POSTCODE\n",
      "0  DOYLE OVERTON RD     78719\n",
      "1           MAHA RD     78719\n",
      "2       POCMONT TRL     78719\n",
      "3         EVELYN RD     78747\n",
      "4         S SH 45 E     78747\n",
      "5     S SH 130 SVRD     78719\n",
      "6      MAHA LOOP RD     78719\n",
      "7      S US 183 HWY     78719\n",
      "8      S US 183 HWY     78747\n",
      "9    TOM SASSMAN RD     78747\n"
     ]
    }
   ],
   "source": [
    "df2_unique_streets_zipcode = pd.read_csv(r'C:\\Users\\Utente\\df2_unique_streets_zipcode.csv')\n",
    "print(df2_unique_streets_zipcode.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3793bc9-d8aa-4a02-945f-1e92585e3011",
   "metadata": {},
   "source": [
    "##to find how many unique cities matches in 2 different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6feff4fc-b1f4-42bd-ae48-6f8cf125fb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: 1987\n"
     ]
    }
   ],
   "source": [
    "#Integerating 2 datasets\n",
    "common = set(df1_unique_streets_only[\"street_clean1\"]) & set(df2_unique_streets_zipcode[\"street_clean2\"])\n",
    "# Remove 'nan' or empty strings if they aren't real cities -> Data Quality\n",
    "common.discard('NAN') \n",
    "common.discard('')\n",
    "common.discard('nan')\n",
    "print(\"Matches:\", len(common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aca0664d-a296-4676-bf91-d0254db343a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common ZIPs: 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{78701,\n",
       " 78702,\n",
       " 78703,\n",
       " 78704,\n",
       " 78705,\n",
       " 78721,\n",
       " 78722,\n",
       " 78723,\n",
       " 78724,\n",
       " 78725,\n",
       " 78726,\n",
       " 78727,\n",
       " 78728,\n",
       " 78729,\n",
       " 78730,\n",
       " 78731,\n",
       " 78732,\n",
       " 78733,\n",
       " 78735,\n",
       " 78736,\n",
       " 78737,\n",
       " 78738,\n",
       " 78739,\n",
       " 78741,\n",
       " 78742,\n",
       " 78744,\n",
       " 78745,\n",
       " 78746,\n",
       " 78747,\n",
       " 78748,\n",
       " 78749,\n",
       " 78750,\n",
       " 78751,\n",
       " 78752,\n",
       " 78753,\n",
       " 78754,\n",
       " 78756,\n",
       " 78757,\n",
       " 78758,\n",
       " 78759}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neigh = pd.read_csv(r'C:\\courses\\DataManagement and Vis\\project\\austin_zip_to_neighborhood_full.csv')\n",
    "df_pop = pd.read_csv(r'C:\\courses\\DataManagement and Vis\\project\\austin_population_by_zip_scraped.csv')\n",
    "valid_pop = df_pop[df_pop[\"Population\"] > 0]\n",
    "\n",
    "zip_neigh = set(df_neigh[\"ZIP_Code\"])\n",
    "zip_pop_valid = set(valid_pop[\"ZIP_Code\"])\n",
    "zip_street = set(df2_unique_streets_zipcode[\"POSTCODE\"])\n",
    "\n",
    "common_zips = zip_neigh & zip_pop_valid & zip_street\n",
    "\n",
    "print(\"Common ZIPs:\", len(common_zips))\n",
    "common_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24fc2591-f816-450f-b85f-9467d29eb677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP codes found in matched streets: 43\n",
      "ZIP codes in your valid pool (Neighborhood/Pop/Street): 40\n",
      "---\n",
      "Shared ZIP codes (Matches): 40\n"
     ]
    }
   ],
   "source": [
    "# 1. Get the set of ZIP codes associated ONLY with the streets in 'common'\n",
    "# We look at df2 to find the POSTCODE for every street that exists in 'common'\n",
    "zips_from_matched_streets = set(df2_unique_streets_zipcode[\n",
    "    df2_unique_streets_zipcode['street_clean2'].isin(common)\n",
    "]['POSTCODE'])\n",
    "\n",
    "# 2. Find the intersection between matched street ZIPs and valid pool (common_zips)\n",
    "final_overlap = zips_from_matched_streets & common_zips\n",
    "\n",
    "print(f\"ZIP codes found in matched streets: {len(zips_from_matched_streets)}\")\n",
    "print(f\"ZIP codes in your valid pool (Neighborhood/Pop/Street): {len(common_zips)}\")\n",
    "print(f\"---\")\n",
    "print(f\"Shared ZIP codes (Matches): {len(final_overlap)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
